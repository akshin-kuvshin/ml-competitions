{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/danilaaxyonov/cifar-100-image-recognition-using-cnn?scriptVersionId=262918227\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"4f4ad589","metadata":{"papermill":{"duration":0.003045,"end_time":"2025-09-20T05:44:09.031374","exception":false,"start_time":"2025-09-20T05:44:09.028329","status":"completed"},"tags":[]},"source":["### Hello everyone. In this notebook I'll try to build a CNN for recognition images from CIFAR-100 dataset. That's my first time of using CNN, so I don't know how to choose architecture for my model (number of convolutional layers, kernel's size, number of fully-connected flat layers). I hope that I'll beat 99% accuracy. Wish me luck!"]},{"cell_type":"markdown","id":"7c9e0509","metadata":{"papermill":{"duration":0.002282,"end_time":"2025-09-20T05:44:09.036558","exception":false,"start_time":"2025-09-20T05:44:09.034276","status":"completed"},"tags":[]},"source":["# 0. Setup."]},{"cell_type":"code","execution_count":1,"id":"aa8e0ed7","metadata":{"execution":{"iopub.execute_input":"2025-09-20T05:44:09.042226Z","iopub.status.busy":"2025-09-20T05:44:09.041728Z","iopub.status.idle":"2025-09-20T05:44:18.503699Z","shell.execute_reply":"2025-09-20T05:44:18.502816Z"},"papermill":{"duration":9.466203,"end_time":"2025-09-20T05:44:18.504991","exception":false,"start_time":"2025-09-20T05:44:09.038788","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Current device: cuda\n","Setup completed.\n"]}],"source":["import torch\n","from torch import nn, optim\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import v2 # recommended by developers themselves!\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Current device:', device)\n","\n","print('Setup completed.')"]},{"cell_type":"markdown","id":"028f75a8","metadata":{"papermill":{"duration":0.002272,"end_time":"2025-09-20T05:44:18.50999","exception":false,"start_time":"2025-09-20T05:44:18.507718","status":"completed"},"tags":[]},"source":["# 1. Loading and normalizing CIFAR-100 dataset."]},{"cell_type":"code","execution_count":2,"id":"420685ce","metadata":{"execution":{"iopub.execute_input":"2025-09-20T05:44:18.515874Z","iopub.status.busy":"2025-09-20T05:44:18.515175Z","iopub.status.idle":"2025-09-20T05:44:18.520302Z","shell.execute_reply":"2025-09-20T05:44:18.51936Z"},"papermill":{"duration":0.009193,"end_time":"2025-09-20T05:44:18.521507","exception":false,"start_time":"2025-09-20T05:44:18.512314","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CIFAR100_unnormalized_transform created.\n"]}],"source":["CIFAR100_unnormalized_transform = v2.Compose([\n","    v2.ToImage(), # dtype=torch.uint8; from 0 to 255 inclusively.\n","    v2.ToDtype(torch.float32) # still from 0 to 255 inclusively.\n","])\n","print('CIFAR100_unnormalized_transform created.')"]},{"cell_type":"code","execution_count":3,"id":"f651a089","metadata":{"execution":{"iopub.execute_input":"2025-09-20T05:44:18.52792Z","iopub.status.busy":"2025-09-20T05:44:18.527204Z","iopub.status.idle":"2025-09-20T05:44:26.455247Z","shell.execute_reply":"2025-09-20T05:44:26.454379Z"},"papermill":{"duration":7.932369,"end_time":"2025-09-20T05:44:26.456382","exception":false,"start_time":"2025-09-20T05:44:18.524013","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 169M/169M [00:04<00:00, 39.2MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Unnormalized CIFAR-100 dataset loaded.\n"]}],"source":["train = datasets.CIFAR100(\n","    root='./',\n","    download=True,\n","    train=True,\n","    transform=CIFAR100_unnormalized_transform\n",")\n","test = datasets.CIFAR100(\n","    root='./',\n","    download=True,\n","    train=False,\n","    transform=CIFAR100_unnormalized_transform\n",")\n","print('Unnormalized CIFAR-100 dataset loaded.')"]},{"cell_type":"code","execution_count":4,"id":"d594c665","metadata":{"execution":{"iopub.execute_input":"2025-09-20T05:44:26.466211Z","iopub.status.busy":"2025-09-20T05:44:26.465982Z","iopub.status.idle":"2025-09-20T05:44:59.998103Z","shell.execute_reply":"2025-09-20T05:44:59.997253Z"},"papermill":{"duration":33.541825,"end_time":"2025-09-20T05:45:00.003064","exception":false,"start_time":"2025-09-20T05:44:26.461239","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["mean: tensor([129.3773, 124.1058, 112.4776])\n","std: tensor([68.2095, 65.4312, 70.4587])\n"]}],"source":["r = torch.stack([train[i][0][0] for i in range(len(train))] + [test[i][0][0] for i in range(len(test))]).to(device) # red\n","g = torch.stack([train[i][0][1] for i in range(len(train))] + [test[i][0][1] for i in range(len(test))]).to(device) # green\n","b = torch.stack([train[i][0][2] for i in range(len(train))] + [test[i][0][2] for i in range(len(test))]).to(device) # blue\n","\n","CIFAR100_mean = torch.Tensor([\n","    r.mean().item(),\n","    g.mean().item(),\n","    b.mean().item()\n","])\n","CIFAR100_std = torch.Tensor([\n","    r.std().item(),\n","    g.std().item(),\n","    b.std().item()\n","])\n","print('mean:', CIFAR100_mean)\n","print('std:', CIFAR100_std)\n","\n","del r, g, b # to free memory."]},{"cell_type":"code","execution_count":5,"id":"8159630e","metadata":{"execution":{"iopub.execute_input":"2025-09-20T05:45:00.012949Z","iopub.status.busy":"2025-09-20T05:45:00.012702Z","iopub.status.idle":"2025-09-20T05:45:00.016983Z","shell.execute_reply":"2025-09-20T05:45:00.016251Z"},"papermill":{"duration":0.010328,"end_time":"2025-09-20T05:45:00.018018","exception":false,"start_time":"2025-09-20T05:45:00.00769","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CIFAR100_normalized_transform created.\n"]}],"source":["CIFAR100_normalized_transform = v2.Compose([\n","    CIFAR100_unnormalized_transform,\n","    v2.Normalize(mean=CIFAR100_mean, std=CIFAR100_std) # niceee)\n","])\n","print('CIFAR100_normalized_transform created.')"]},{"cell_type":"code","execution_count":6,"id":"73bbc393","metadata":{"execution":{"iopub.execute_input":"2025-09-20T05:45:00.028091Z","iopub.status.busy":"2025-09-20T05:45:00.027716Z","iopub.status.idle":"2025-09-20T05:45:01.793155Z","shell.execute_reply":"2025-09-20T05:45:01.792347Z"},"papermill":{"duration":1.771251,"end_time":"2025-09-20T05:45:01.794327","exception":false,"start_time":"2025-09-20T05:45:00.023076","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Normalized CIFAR-100 dataset loaded.\n"]}],"source":["train = datasets.CIFAR100(\n","    root='./',\n","    download=True,\n","    train=True,\n","    transform=CIFAR100_normalized_transform\n",")\n","test = datasets.CIFAR100(\n","    root='./',\n","    download=True,\n","    train=False,\n","    transform=CIFAR100_normalized_transform\n",")\n","print('Normalized CIFAR-100 dataset loaded.')"]},{"cell_type":"markdown","id":"8cacf02e","metadata":{"papermill":{"duration":0.004075,"end_time":"2025-09-20T05:45:01.802851","exception":false,"start_time":"2025-09-20T05:45:01.798776","status":"completed"},"tags":[]},"source":["# 2. Creating a Dataloader."]},{"cell_type":"code","execution_count":7,"id":"461ab548","metadata":{"execution":{"iopub.execute_input":"2025-09-20T05:45:01.811762Z","iopub.status.busy":"2025-09-20T05:45:01.811555Z","iopub.status.idle":"2025-09-20T05:45:01.816152Z","shell.execute_reply":"2025-09-20T05:45:01.815367Z"},"papermill":{"duration":0.010273,"end_time":"2025-09-20T05:45:01.817157","exception":false,"start_time":"2025-09-20T05:45:01.806884","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Both DataLoaders created.\n"]}],"source":["BATCH_SIZE = 256 # don't change my traditions)\n","\n","train_DL = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n","test_DL = DataLoader(test, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n","\n","print('Both DataLoaders created.')"]},{"cell_type":"code","execution_count":8,"id":"a75384cb","metadata":{"execution":{"iopub.execute_input":"2025-09-20T05:45:01.826166Z","iopub.status.busy":"2025-09-20T05:45:01.825966Z","iopub.status.idle":"2025-09-20T05:45:02.077472Z","shell.execute_reply":"2025-09-20T05:45:02.07628Z"},"papermill":{"duration":0.257578,"end_time":"2025-09-20T05:45:02.078974","exception":false,"start_time":"2025-09-20T05:45:01.821396","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([256, 3, 32, 32])\n","torch.Size([256])\n"]}],"source":["batch_example = next(iter(train_DL))\n","print(batch_example[0].shape)\n","print(batch_example[1].shape)"]},{"cell_type":"markdown","id":"9eea2387","metadata":{"papermill":{"duration":0.0044,"end_time":"2025-09-20T05:45:02.088201","exception":false,"start_time":"2025-09-20T05:45:02.083801","status":"completed"},"tags":[]},"source":["# 3. Choosing a CNN's architecture and writing a model class."]},{"cell_type":"code","execution_count":9,"id":"41421262","metadata":{"execution":{"iopub.execute_input":"2025-09-20T05:45:02.098145Z","iopub.status.busy":"2025-09-20T05:45:02.0979Z","iopub.status.idle":"2025-09-20T05:45:02.106677Z","shell.execute_reply":"2025-09-20T05:45:02.10609Z"},"papermill":{"duration":0.015145,"end_time":"2025-09-20T05:45:02.10778","exception":false,"start_time":"2025-09-20T05:45:02.092635","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CIFAR100CNN class created.\n"]}],"source":["class CIFAR100CNN(nn.Module):\n","    def __init__(self) -> None:\n","        super().__init__()\n","\n","        self.features = nn.Sequential(\n","            # now input.shape == (3, 32, 32).\n","            \n","            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding='same'), # padding='same' means (in.h, in.w) == (out.h, out.w).\n","            # now input.shape == (32, 32, 32).\n","            nn.ReLU(), # adding non-linearity, because Conv2d is linear and ReLU(x) = max(x, 0) is non-linear.\n","            nn.Dropout2d(p=0.15),\n","            \n","            nn.MaxPool2d(kernel_size=2, stride=2), # kernel_size == stride   ==>   non-crossing applications of the same kernel.\n","            # now input.shape == (32, 16, 16).\n","            \n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding='same'),\n","            # now input.shap == (64, 16, 16).\n","            nn.ReLU(),\n","            nn.Dropout2d(p=0.15),\n","\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","            # now input.shape == (64, 8, 8).\n","        )\n","\n","        self.classifier = nn.Sequential(\n","            nn.Flatten(), # (64, 8, 8) => (64 * 8 * 8,) somehow.\n","            # 64 * 8 * 8 = 4'096.\n","            \n","            nn.Linear(4096, 2048),\n","            nn.ReLU(),\n","            nn.Dropout(p=0.4),\n","            \n","            nn.Linear(2048, 1024),\n","            nn.ReLU(),\n","            nn.Dropout(p=0.4),\n","            \n","            nn.Linear(1024, 512),\n","            nn.ReLU(),\n","            nn.Dropout(p=0.4),\n","            \n","            nn.Linear(512, 256),\n","            nn.ReLU(),\n","            nn.Dropout(p=0.4),\n","            \n","            nn.Linear(256, 100),\n","            nn.Softmax() # not necessary actually.\n","        )\n","\n","        return\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        x = self.features(x)\n","        x = self.classifier(x)\n","        return x\n","\n","print('CIFAR100CNN class created.')"]},{"cell_type":"markdown","id":"80c27deb","metadata":{"papermill":{"duration":0.00408,"end_time":"2025-09-20T05:45:02.116189","exception":false,"start_time":"2025-09-20T05:45:02.112109","status":"completed"},"tags":[]},"source":["# 4. Creating a model itself."]},{"cell_type":"code","execution_count":10,"id":"72350007","metadata":{"execution":{"iopub.execute_input":"2025-09-20T05:45:02.125891Z","iopub.status.busy":"2025-09-20T05:45:02.125299Z","iopub.status.idle":"2025-09-20T05:45:02.223395Z","shell.execute_reply":"2025-09-20T05:45:02.222778Z"},"papermill":{"duration":0.103929,"end_time":"2025-09-20T05:45:02.224362","exception":false,"start_time":"2025-09-20T05:45:02.120433","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Model, loss function and optimizer created.\n"]}],"source":["model = CIFAR100CNN().to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","print('Model, loss function and optimizer created.')"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"papermill":{"default_parameters":{},"duration":59.028276,"end_time":"2025-09-20T05:45:03.748371","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-09-20T05:44:04.720095","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}